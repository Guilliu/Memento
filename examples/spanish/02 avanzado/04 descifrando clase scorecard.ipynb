{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se revela paso a paso el `funcionamiento interno` de la clase Scorecard en su modo automático.<br>Usamos el mismo dataset del ejemplo 01 para ir comprobando los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Importamos los módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pandas as pd, memento as me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer as lbc\n",
    "X, y = pd.DataFrame(lbc().data, columns=lbc().feature_names), lbc().target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Sustituimos los espacios en blanco por guiones bajos en el nombre de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns = [i.replace(' ', '_') for i in X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Lo primero que hace la clase `Scorecard` es generar una partición train-test. Por defecto hace un 70-30, estratificado en el target y con semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "X_train, X_test = X_train.reset_index(drop=True), X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Después, aplica la clase `Autogrouping` a todas las variables y guarda los objetos resultantes en un diccionario.<br> Para generar estos buckets automáticos se usan árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables, autogroupings = X_train.columns, {}\n",
    "variables_no_agrupadas_error = []\n",
    "for variable in variables:\n",
    "    try:\n",
    "        x = X_train[variable].values\n",
    "        frenken = me.Autogrouping().fit(x, y_train)\n",
    "        autogroupings[variable] = frenken\n",
    "    except: variables_no_agrupadas_error.append(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>También genera un DataFrame ordenado por IV. No considerará a las variables que tengan un IV inverior al umbral mínimo metodológico (0.015, modificable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_ivs, contador = pd.DataFrame(columns=['variable', 'iv']), 0\n",
    "for variable in autogroupings:\n",
    "    tabla_ivs.loc[contador] = variable, autogroupings[variable].iv\n",
    "    contador += 1\n",
    "tabla_ivs = tabla_ivs.sort_values('iv', ascending=False).reset_index(drop=True)\n",
    "variables_filtro_iv = tabla_ivs[tabla_ivs['iv'] >= 0.015]['variable']\n",
    "variables_def = list(set(variables_filtro_iv) - set(variables_no_agrupadas_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Vemos cuáles son las variables con mayor IV (= Information Value). Podríamos probar a generar una scorecard seleccionando las n variables de mayor IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>iv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worst_concave_points</td>\n",
       "      <td>6.377094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worst_radius</td>\n",
       "      <td>6.169409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worst_perimeter</td>\n",
       "      <td>6.148091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               variable        iv\n",
       "0  worst_concave_points  6.377094\n",
       "1          worst_radius  6.169409\n",
       "2       worst_perimeter  6.148091"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_ivs.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Por ejemplo, veamos cómo sería la scorecard con las tres primeras variables por IV: `worst_concave_points`, `worst_radius`, `worst_perimeter`.<br> En **features** pondríamos las variables que queremos que formen parte de la scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['worst_concave_points', 'worst_radius', 'worst_perimeter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Si quisiéramos usar agrupaciones manuales las pondríamos dentro del diccionario **user_breakpoints**, por ahora lo dejamos vacío para usar las automáticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_breakpoints = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>En **final_breakpoints** se actualizarían los grupos en caso de haber introducido agrupaciones manuales en user_breakpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_breakpoints = me.compute_final_breakpoints(variables_def, autogroupings, user_breakpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Antes de calcular el modelo, la clase Scorecard aplica un **tratamiento** a las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = me.compute_info(X_train, variables_def, final_breakpoints)\n",
    "df_train = me.adapt_data(X_train, y_train, variables_def, final_breakpoints, 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Calculamos ya la scorecard, pero solo como **tarjeta de puntuación** en forma de DataFrame, el objeto tipo modelo se obtiene usando clase Scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard, features_length = me.compute_scorecard(df_train, features, info, 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Podemos aplicar esta tarjeta de puntuación al data de entrenamiento y ver las métricas asociadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El  modelo tiene un 89.82% de KS y un 97.66% de Gini en esta muestra\n"
     ]
    }
   ],
   "source": [
    "df_train_final = me.apply_scorecard(df_train, scorecard, info, 'target')\n",
    "ks_train, gini_train = me.compute_metrics(df_train_final, 'target', ['gini', 'ks'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Hacemos lo mismo con los datos del test (la validación del 30%, habitualmente llamada **hold out**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El  modelo tiene un 92.20% de KS y un 97.63% de Gini en esta muestra\n"
     ]
    }
   ],
   "source": [
    "df_test = me.adapt_data(X_test, y_test, variables_def, final_breakpoints, 'target')\n",
    "df_test_final = me.apply_scorecard(df_test, scorecard, info, 'target')\n",
    "ks_test, gini_test = me.compute_metrics(df_test_final, 'target', ['gini', 'ks'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>No ha salido un mal modelo, también porque este ejemplo es MUY de juguete... La clase Scorecard hace todo igual que hasta ahora salvo la selección de variables: no elige las variables en función de su IV sino que se utilizan una de estas dos aproximaciones.<br>(Disclaimer: esto es algo muy teórico, no es necesario comprenderlo perfectamente ni mucho menos)\n",
    "    \n",
    "1) **Método `forward` con métrica de `ks` o `gini`**:  En el primer paso se parte del modelo vacío, es decir el modelo que no tiene ninguna variable. Entonces para cada variable candidata (aquellas agrupadas con un IV >= 0.015) se genera un modelo que tienen a esa variable como única variable del modelo, así de entre todos estos modelos univariable se mira cual sería el que da un mayor valor de la métrica (ks o gini) en el data  del train. Aquella variable cuyo modelo de el MÁXIMO valor de la métrica se selecciona. En el segundo paso se parte del conjunto que ya tiene la primera variable seleccionada del paso anterior. Ahora, se consideran TODAS las demás variables candidatas para generar TODOS los modelos de dos variables distintos posibles donde la primera es la que ya habíamos seleccionado en el paso anterior. Bien, pues de entre todos estos modelos 2-variables aquel que de el MÁXIMO valor de la métrica en el train nos indica cual es la segunda variable que seleccionamos: la que se ha añadido a la que ya teníamos para generar este modelo. Note que, si el número de variables candidatas es n, entonces en el paso 1 se consideran n modelos 1-variable y en el paso 2 se considerarían (n-1) modelos 2-variables, sin embargo, estos modelos 2-variables son más costosos desde el punto de vista computacional por tener una variable más y esto hace que los tiempos vayan aumentando en cada paso. El proceso se detiene cuando se alcanza el máximo número de pasos permitidos o cuando la métrica no mejora más de un umbral (0.20 para KS y 0.30 para Gini) la del paso anterior.\n",
    "    \n",
    "2) **Método `stepwise` con métrica de `p-valor` (configuración por defecto de la clase Scorecard)**: Se realiza un forward como el anteriormente descrito, pero con algunas modificaciones. Se empieza buscando la variable que genera el modelo 1-variable en donde esta variable tiene el p-valor más bajo (los p-valores se calculan a nivel variable, no a nivel modelo). En un segundo paso se consideran todos los modelos 2-variables donde la primera variable es la elegida en el paso anterior y la segunda es cualquiera de las candidatas restantes. Bien, pues en cada uno de  estos modelos se CALCULAN los p-valores de las dos variables y se elige el que tenga el p-valor  de la variable que se está probando más bajo. La gracia ahora es que aquí en cada paso se RECALCULAN los p-valores de TODAS las variables  involucradas en el modelo de turno, no solo el de la variable candidata a entrar si no también los p-valores del resto de variables ya seleccionadas de forma que si en algún momento alguno de ellos es superior a 0.01 (nivel de significancia metodológico) entonces esta variable SALE  del modelo. Esto ocurrirá cuando la variable que acaba de entrar está ciertamente correlada con  la que está saliendo pero por algún motivo la que entra se combina mejor con el resto de variables del modelo y tiene una aportación 'mayor' al modelo (estadísticamente hablando). El proceso se detiene cuando se alcanza el máximo número de pasos permitidos o cuando ninguna de las variables retadas tiene un p-valor inferior a 0.01 o también cuando la métrica no mejora más de un umbral (0.20 para KS y 0.30 para Gini)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>La función `feature_selection` realiza este proceso, la usamos con sus valores por defecto para obtener las mismas variables que en el ejemplo 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 01 | 0:00:00.482512 | pv = 4.92e-32 | Gini train = 83.97% ---> Feature selected: mean_concavity\n",
      "Step 02 | 0:00:00.551811 | pv = 1.38e-14 | Gini train = 96.82% ---> Feature selected: worst_perimeter\n",
      "Step 03 | 0:00:00.693677 | pv = 4.31e-06 | Gini train = 98.34% ---> Feature selected: worst_texture\n",
      "Step 04 | 0:00:00.726164 | pv = 5.11e-04 | Gini train = 98.92% ---> Feature selected: worst_smoothness\n",
      "Step 05 | 0:00:00.828861 | pv = 1.62e-03 | Gini train = 99.34% ---> Feature selected: radius_error\n",
      "Step 06 | 0:00:00.844320 | pv = 2.28e-03 | Gini train = 99.60% ---> Feature selected: worst_concavity\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Ya ninguna variable tiene un p-valor < 0.01, detenemos el proceso\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Selección terminada: ['worst_perimeter', 'worst_texture', 'worst_smoothness', 'radius_error', 'worst_concavity']\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "features = me.features_selection(df_train, [], variables_def, info, 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Ahora sí la scorecard sale igual que ene ejemplo 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El  modelo tiene un 95.55% de KS y un 99.60% de Gini en esta muestra\n",
      "--------------------------------------------------------------------------------\n",
      "El  modelo tiene un 95.63% de KS y un 98.77% de Gini en esta muestra\n"
     ]
    }
   ],
   "source": [
    "scorecard, features_length = me.compute_scorecard(df_train, features, info, 'target')\n",
    "df_train_final = me.apply_scorecard(df_train, scorecard, info, 'target')\n",
    "df_test_final = me.apply_scorecard(df_test, scorecard, info, 'target')\n",
    "ks_train, gini_train = me.compute_metrics(df_train_final, 'target', ['gini', 'ks'], True)\n",
    "print('-'*80)\n",
    "ks_test, gini_test = me.compute_metrics(df_test_final, 'target', ['gini', 'ks'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucario",
   "language": "python",
   "name": "lucario"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
